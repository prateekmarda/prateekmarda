{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc0569076697426d91e9f747771b3d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f922fd701d924138946601803d880ba9",
              "IPY_MODEL_7489d8e4cc3d45c7bf2bdf57b7db57c3",
              "IPY_MODEL_50311600339f4a9a91899a7d09244010"
            ],
            "layout": "IPY_MODEL_51fdb7c3ce704b5880d69fd2a0b30b49"
          }
        },
        "f922fd701d924138946601803d880ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e86c9b5462c4bbeb07996c80fb22304",
            "placeholder": "​",
            "style": "IPY_MODEL_06dd46170651417dbe0ca1fd75476f9e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7489d8e4cc3d45c7bf2bdf57b7db57c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24760f9ec78b4173839f40c8effa084d",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c7981c368854b18ab206f260e309619",
            "value": 2324
          }
        },
        "50311600339f4a9a91899a7d09244010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ed2106e33714fe083907b94fcef8f79",
            "placeholder": "​",
            "style": "IPY_MODEL_989fc79e0ebe48a68b3bff39175c79ec",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 260kB/s]"
          }
        },
        "51fdb7c3ce704b5880d69fd2a0b30b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e86c9b5462c4bbeb07996c80fb22304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06dd46170651417dbe0ca1fd75476f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24760f9ec78b4173839f40c8effa084d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7981c368854b18ab206f260e309619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ed2106e33714fe083907b94fcef8f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989fc79e0ebe48a68b3bff39175c79ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "992d9be7abb1435e8098b0c8bd96bebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a8e441c20d44278b465ffeab1c09eda",
              "IPY_MODEL_66c36626b8b44000ab0144632cce4bb9",
              "IPY_MODEL_69d82a104d6d492391d99360e948244e"
            ],
            "layout": "IPY_MODEL_8b94ae3516e5411f8246938c1cbb8b2d"
          }
        },
        "9a8e441c20d44278b465ffeab1c09eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f57af1983ae74f64934c88cf1382987c",
            "placeholder": "​",
            "style": "IPY_MODEL_3be50272f3e74f35a67fb4a55fe8acb2",
            "value": "spiece.model: 100%"
          }
        },
        "66c36626b8b44000ab0144632cce4bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_529ea5240f4a49e3b04c49531e854b70",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9318bd1f7d594091a5226e334f6843dc",
            "value": 791656
          }
        },
        "69d82a104d6d492391d99360e948244e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec19137b6d9146298351bd2b19b8eef0",
            "placeholder": "​",
            "style": "IPY_MODEL_f926ef388d6841a3aac537ee430a1377",
            "value": " 792k/792k [00:00&lt;00:00, 3.15MB/s]"
          }
        },
        "8b94ae3516e5411f8246938c1cbb8b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57af1983ae74f64934c88cf1382987c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be50272f3e74f35a67fb4a55fe8acb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "529ea5240f4a49e3b04c49531e854b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9318bd1f7d594091a5226e334f6843dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec19137b6d9146298351bd2b19b8eef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f926ef388d6841a3aac537ee430a1377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "948c420188d94005ac47bc4c3fa25e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef60e8083c234173b3f0f5b5448eb8c2",
              "IPY_MODEL_703b0d4a3e5f4d78ab3b0a1d6d3f793e",
              "IPY_MODEL_577af18bbd484cff80206a9a4ef366ab"
            ],
            "layout": "IPY_MODEL_7501381610794b768bbdc791e32eb177"
          }
        },
        "ef60e8083c234173b3f0f5b5448eb8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06dbc484ada74f4e9ed37536d4f26fc2",
            "placeholder": "​",
            "style": "IPY_MODEL_fecdfa6dce5e4b1ead864cf7b5ace577",
            "value": "tokenizer.json: 100%"
          }
        },
        "703b0d4a3e5f4d78ab3b0a1d6d3f793e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db95c1660a414dce95c9c7139ec1f685",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beddbfc939624627956376afb7a78d50",
            "value": 1389353
          }
        },
        "577af18bbd484cff80206a9a4ef366ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0f739c0a7444aead8324453accb0e6",
            "placeholder": "​",
            "style": "IPY_MODEL_7e5ee752c53743cab5df88a7e98162b2",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 5.64MB/s]"
          }
        },
        "7501381610794b768bbdc791e32eb177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06dbc484ada74f4e9ed37536d4f26fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fecdfa6dce5e4b1ead864cf7b5ace577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db95c1660a414dce95c9c7139ec1f685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beddbfc939624627956376afb7a78d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f0f739c0a7444aead8324453accb0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e5ee752c53743cab5df88a7e98162b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekmarda/prateekmarda/blob/main/onyx%20and%20tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorRT"
      ],
      "metadata": {
        "id": "O4G0UbnvobV5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aakJoogRTQc9",
        "outputId": "62adb396-ab9b-42bd-fcb6-43a114e79432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (1.14.0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (300.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, onnx, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.20.0 onnxruntime-gpu-1.23.2\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime-gpu onnx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx -O resnet50.onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNsF9Wzmq-fz",
        "outputId": "3ee49be0-c160-4605-bd54-197d9e41186e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-01 10:26:39--  https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/onnx/models/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx [following]\n",
            "--2026-01-01 10:26:39--  https://media.githubusercontent.com/media/onnx/models/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102442452 (98M) [application/octet-stream]\n",
            "Saving to: ‘resnet50.onnx’\n",
            "\n",
            "resnet50.onnx       100%[===================>]  97.70M  28.2MB/s    in 3.5s    \n",
            "\n",
            "2026-01-01 10:26:43 (27.6 MB/s) - ‘resnet50.onnx’ saved [102442452/102442452]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "F84L5PXFrZlB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ONNX model with CUDA provider only\n",
        "sess = ort.InferenceSession(\n",
        "    \"resnet50.onnx\",\n",
        "    providers=[\"CUDAExecutionProvider\"]  # Remove TensorRT\n",
        ")\n",
        "\n",
        "print(\"Providers:\", sess.get_providers())\n",
        "\n",
        "# Prepare input data\n",
        "input_name = sess.get_inputs()[0].name\n",
        "input_data = np.random.random((1, 3, 224, 224)).astype(np.float32)\n",
        "\n",
        "# Run inference\n",
        "output = sess.run(None, {input_name: input_data})\n",
        "print(\"Output shape:\", output[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVxf6twMr3u0",
        "outputId": "4d3e0369-05a6-45d6-b240-99f5d2a1e925"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Output shape: (1, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import onnx\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import time\n",
        "import torch\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "f8ZLdDTbr8b0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load a pre-trained PyTorch model\n",
        "print(\"Loading pre-trained ResNet-18 model...\")\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nqwEjRXtTDp",
        "outputId": "b057abd0-c91d-45bf-ec7b-bec24333de1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained ResNet-18 model...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define model inputs and output file\n",
        "model_file = \"resnet18.onnx\"\n",
        "input_shape = (1, 3, 224, 224) # Standard ImageNet input size\n",
        "dummy_input = torch.randn(*input_shape)"
      ],
      "metadata": {
        "id": "4vTvUgzatYno"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJtqHvLCHkyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxscript\n",
        "# 3. Export the model to ONNX format\n",
        "print(f\"Exporting PyTorch model to {model_file}...\")\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    model_file,\n",
        "    export_params=True,\n",
        "    opset_version=12,  # Compatible ONNX Opset Version\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"input_tensor\"],\n",
        "    output_names=[\"output_tensor\"],\n",
        "    dynamic_axes={'input_tensor': {0: 'batch_size'}} # Allow dynamic batch size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BpBmoCut3jt",
        "outputId": "a900c1f6-535c-40c9-f424-15f9e6b366bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (1.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n",
            "Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/693.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m686.1/693.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/133.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx_ir, onnxscript\n",
            "Successfully installed onnx_ir-0.1.13 onnxscript-0.5.7\n",
            "Exporting PyTorch model to resnet18.onnx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1521737941.py:4: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W0101 10:33:45.783000 800 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 40 of general pattern rewrite rules.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ONNXProgram(\n",
              "    model=\n",
              "        <\n",
              "            ir_version=10,\n",
              "            opset_imports={'': 18},\n",
              "            producer_name='pytorch',\n",
              "            producer_version='2.9.0+cu126',\n",
              "            domain=None,\n",
              "            model_version=None,\n",
              "        >\n",
              "        graph(\n",
              "            name=main_graph,\n",
              "            inputs=(\n",
              "                %\"input_tensor\"<FLOAT,[s77,3,224,224]>\n",
              "            ),\n",
              "            outputs=(\n",
              "                %\"output_tensor\"<FLOAT,[1,1000]>\n",
              "            ),\n",
              "            initializers=(\n",
              "                %\"fc.bias\"<FLOAT,[1000]>{TorchTensor(...)},\n",
              "                %\"conv1.weight\"<FLOAT,[64,3,7,7]>{Tensor(...)},\n",
              "                %\"layer1.0.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
              "                %\"layer1.0.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
              "                %\"layer1.1.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
              "                %\"layer1.1.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
              "                %\"layer2.0.conv1.weight\"<FLOAT,[128,64,3,3]>{Tensor(...)},\n",
              "                %\"layer2.0.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
              "                %\"layer2.0.downsample.0.weight\"<FLOAT,[128,64,1,1]>{Tensor(...)},\n",
              "                %\"layer2.1.conv1.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
              "                %\"layer2.1.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
              "                %\"layer3.0.conv1.weight\"<FLOAT,[256,128,3,3]>{Tensor(...)},\n",
              "                %\"layer3.0.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.0.downsample.0.weight\"<FLOAT,[256,128,1,1]>{Tensor(...)},\n",
              "                %\"layer3.1.conv1.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.1.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer4.0.conv1.weight\"<FLOAT,[512,256,3,3]>{Tensor(...)},\n",
              "                %\"layer4.0.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
              "                %\"layer4.0.downsample.0.weight\"<FLOAT,[512,256,1,1]>{Tensor(...)},\n",
              "                %\"layer4.1.conv1.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
              "                %\"layer4.1.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
              "                %\"fc.weight\"<FLOAT,[1000,512]>{TorchTensor(...)},\n",
              "                %\"val_186\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_186')},\n",
              "                %\"val_190\"<INT64,[2]>{Tensor<INT64,[2]>(array([  1, 512]), name='val_190')},\n",
              "                %\"conv1.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.0.conv1.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.0.conv2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.1.conv1.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.1.conv2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer2.0.conv1.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.0.conv2.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.0.downsample.0.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.1.conv1.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.1.conv2.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer3.0.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.0.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.0.downsample.0.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.1.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.1.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer4.0.conv1.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.0.conv2.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.0.downsample.0.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.1.conv1.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.1.conv2.weight_bias\"<FLOAT,[512]>{Tensor(...)}\n",
              "            ),\n",
              "        ) {\n",
              "             0 |  # node_Conv_251\n",
              "                  %\"getitem\"<FLOAT,[1,64,112,112]> ⬅️ ::Conv(%\"input_tensor\", %\"conv1.weight\"{...}, %\"conv1.weight_bias\"{...}) {group=1, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             1 |  # node_relu\n",
              "                  %\"relu\"<FLOAT,[1,64,112,112]> ⬅️ ::Relu(%\"getitem\")\n",
              "             2 |  # node_max_pool2d\n",
              "                  %\"max_pool2d\"<FLOAT,[1,64,56,56]> ⬅️ ::MaxPool(%\"relu\") {storage_order=0, dilations=(1, 1), ceil_mode=0, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), kernel_shape=(3, 3)}\n",
              "             3 |  # node_Conv_253\n",
              "                  %\"getitem_3\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"max_pool2d\", %\"layer1.0.conv1.weight\"{...}, %\"layer1.0.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             4 |  # node_relu_1\n",
              "                  %\"relu_1\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_3\")\n",
              "             5 |  # node_Conv_255\n",
              "                  %\"getitem_6\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_1\", %\"layer1.0.conv2.weight\"{...}, %\"layer1.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             6 |  # node_add_5\n",
              "                  %\"add_5\"<FLOAT,[1,64,56,56]> ⬅️ ::Add(%\"getitem_6\", %\"max_pool2d\")\n",
              "             7 |  # node_relu_2\n",
              "                  %\"relu_2\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"add_5\")\n",
              "             8 |  # node_Conv_257\n",
              "                  %\"getitem_9\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_2\", %\"layer1.1.conv1.weight\"{...}, %\"layer1.1.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             9 |  # node_relu_3\n",
              "                  %\"relu_3\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_9\")\n",
              "            10 |  # node_Conv_259\n",
              "                  %\"getitem_12\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_3\", %\"layer1.1.conv2.weight\"{...}, %\"layer1.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            11 |  # node_add_6\n",
              "                  %\"add_6\"<FLOAT,[1,64,56,56]> ⬅️ ::Add(%\"getitem_12\", %\"relu_2\")\n",
              "            12 |  # node_relu_4\n",
              "                  %\"relu_4\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"add_6\")\n",
              "            13 |  # node_Conv_261\n",
              "                  %\"getitem_15\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_4\", %\"layer2.0.conv1.weight\"{...}, %\"layer2.0.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            14 |  # node_relu_5\n",
              "                  %\"relu_5\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_15\")\n",
              "            15 |  # node_Conv_263\n",
              "                  %\"getitem_18\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_5\", %\"layer2.0.conv2.weight\"{...}, %\"layer2.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            16 |  # node_Conv_265\n",
              "                  %\"getitem_21\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_4\", %\"layer2.0.downsample.0.weight\"{...}, %\"layer2.0.downsample.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            17 |  # node_add_7\n",
              "                  %\"add_7\"<FLOAT,[1,128,28,28]> ⬅️ ::Add(%\"getitem_18\", %\"getitem_21\")\n",
              "            18 |  # node_relu_6\n",
              "                  %\"relu_6\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"add_7\")\n",
              "            19 |  # node_Conv_267\n",
              "                  %\"getitem_24\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_6\", %\"layer2.1.conv1.weight\"{...}, %\"layer2.1.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            20 |  # node_relu_7\n",
              "                  %\"relu_7\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_24\")\n",
              "            21 |  # node_Conv_269\n",
              "                  %\"getitem_27\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_7\", %\"layer2.1.conv2.weight\"{...}, %\"layer2.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            22 |  # node_add_8\n",
              "                  %\"add_8\"<FLOAT,[1,128,28,28]> ⬅️ ::Add(%\"getitem_27\", %\"relu_6\")\n",
              "            23 |  # node_relu_8\n",
              "                  %\"relu_8\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"add_8\")\n",
              "            24 |  # node_Conv_271\n",
              "                  %\"getitem_30\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_8\", %\"layer3.0.conv1.weight\"{...}, %\"layer3.0.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            25 |  # node_relu_9\n",
              "                  %\"relu_9\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_30\")\n",
              "            26 |  # node_Conv_273\n",
              "                  %\"getitem_33\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_9\", %\"layer3.0.conv2.weight\"{...}, %\"layer3.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            27 |  # node_Conv_275\n",
              "                  %\"getitem_36\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_8\", %\"layer3.0.downsample.0.weight\"{...}, %\"layer3.0.downsample.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            28 |  # node_add_9\n",
              "                  %\"add_9\"<FLOAT,[1,256,14,14]> ⬅️ ::Add(%\"getitem_33\", %\"getitem_36\")\n",
              "            29 |  # node_relu_10\n",
              "                  %\"relu_10\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"add_9\")\n",
              "            30 |  # node_Conv_277\n",
              "                  %\"getitem_39\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_10\", %\"layer3.1.conv1.weight\"{...}, %\"layer3.1.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            31 |  # node_relu_11\n",
              "                  %\"relu_11\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_39\")\n",
              "            32 |  # node_Conv_279\n",
              "                  %\"getitem_42\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_11\", %\"layer3.1.conv2.weight\"{...}, %\"layer3.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            33 |  # node_add_10\n",
              "                  %\"add_10\"<FLOAT,[1,256,14,14]> ⬅️ ::Add(%\"getitem_42\", %\"relu_10\")\n",
              "            34 |  # node_relu_12\n",
              "                  %\"relu_12\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"add_10\")\n",
              "            35 |  # node_Conv_281\n",
              "                  %\"getitem_45\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_12\", %\"layer4.0.conv1.weight\"{...}, %\"layer4.0.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            36 |  # node_relu_13\n",
              "                  %\"relu_13\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_45\")\n",
              "            37 |  # node_Conv_283\n",
              "                  %\"getitem_48\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_13\", %\"layer4.0.conv2.weight\"{...}, %\"layer4.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            38 |  # node_Conv_285\n",
              "                  %\"getitem_51\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_12\", %\"layer4.0.downsample.0.weight\"{...}, %\"layer4.0.downsample.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            39 |  # node_add_11\n",
              "                  %\"add_11\"<FLOAT,[1,512,7,7]> ⬅️ ::Add(%\"getitem_48\", %\"getitem_51\")\n",
              "            40 |  # node_relu_14\n",
              "                  %\"relu_14\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"add_11\")\n",
              "            41 |  # node_Conv_287\n",
              "                  %\"getitem_54\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_14\", %\"layer4.1.conv1.weight\"{...}, %\"layer4.1.conv1.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            42 |  # node_relu_15\n",
              "                  %\"relu_15\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_54\")\n",
              "            43 |  # node_Conv_289\n",
              "                  %\"getitem_57\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_15\", %\"layer4.1.conv2.weight\"{...}, %\"layer4.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            44 |  # node_add_12\n",
              "                  %\"add_12\"<FLOAT,[1,512,7,7]> ⬅️ ::Add(%\"getitem_57\", %\"relu_14\")\n",
              "            45 |  # node_relu_16\n",
              "                  %\"relu_16\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"add_12\")\n",
              "            46 |  # node_mean\n",
              "                  %\"mean\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"relu_16\", %\"val_186\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
              "            47 |  # node_view\n",
              "                  %\"view\"<FLOAT,[1,512]> ⬅️ ::Reshape(%\"mean\", %\"val_190\"{[1, 512]}) {allowzero=1}\n",
              "            48 |  # node_linear\n",
              "                  %\"output_tensor\"<FLOAT,[1,1000]> ⬅️ ::Gemm(%\"view\", %\"fc.weight\"{...}, %\"fc.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            return %\"output_tensor\"<FLOAT,[1,1000]>\n",
              "        }\n",
              "\n",
              "\n",
              "    ,\n",
              "    exported_program=\n",
              "        ExportedProgram:\n",
              "            class GraphModule(torch.nn.Module):\n",
              "                def forward(self, p_conv1_weight: \"f32[64, 3, 7, 7]\", p_bn1_weight: \"f32[64]\", p_bn1_bias: \"f32[64]\", p_layer1_0_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer1_0_bn1_weight: \"f32[64]\", p_layer1_0_bn1_bias: \"f32[64]\", p_layer1_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_0_bn2_weight: \"f32[64]\", p_layer1_0_bn2_bias: \"f32[64]\", p_layer1_1_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer1_1_bn1_weight: \"f32[64]\", p_layer1_1_bn1_bias: \"f32[64]\", p_layer1_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_1_bn2_weight: \"f32[64]\", p_layer1_1_bn2_bias: \"f32[64]\", p_layer2_0_conv1_weight: \"f32[128, 64, 3, 3]\", p_layer2_0_bn1_weight: \"f32[128]\", p_layer2_0_bn1_bias: \"f32[128]\", p_layer2_0_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_0_bn2_weight: \"f32[128]\", p_layer2_0_bn2_bias: \"f32[128]\", p_layer2_0_downsample_0_weight: \"f32[128, 64, 1, 1]\", p_layer2_0_downsample_1_weight: \"f32[128]\", p_layer2_0_downsample_1_bias: \"f32[128]\", p_layer2_1_conv1_weight: \"f32[128, 128, 3, 3]\", p_layer2_1_bn1_weight: \"f32[128]\", p_layer2_1_bn1_bias: \"f32[128]\", p_layer2_1_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_1_bn2_weight: \"f32[128]\", p_layer2_1_bn2_bias: \"f32[128]\", p_layer3_0_conv1_weight: \"f32[256, 128, 3, 3]\", p_layer3_0_bn1_weight: \"f32[256]\", p_layer3_0_bn1_bias: \"f32[256]\", p_layer3_0_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_0_bn2_weight: \"f32[256]\", p_layer3_0_bn2_bias: \"f32[256]\", p_layer3_0_downsample_0_weight: \"f32[256, 128, 1, 1]\", p_layer3_0_downsample_1_weight: \"f32[256]\", p_layer3_0_downsample_1_bias: \"f32[256]\", p_layer3_1_conv1_weight: \"f32[256, 256, 3, 3]\", p_layer3_1_bn1_weight: \"f32[256]\", p_layer3_1_bn1_bias: \"f32[256]\", p_layer3_1_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_1_bn2_weight: \"f32[256]\", p_layer3_1_bn2_bias: \"f32[256]\", p_layer4_0_conv1_weight: \"f32[512, 256, 3, 3]\", p_layer4_0_bn1_weight: \"f32[512]\", p_layer4_0_bn1_bias: \"f32[512]\", p_layer4_0_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_0_bn2_weight: \"f32[512]\", p_layer4_0_bn2_bias: \"f32[512]\", p_layer4_0_downsample_0_weight: \"f32[512, 256, 1, 1]\", p_layer4_0_downsample_1_weight: \"f32[512]\", p_layer4_0_downsample_1_bias: \"f32[512]\", p_layer4_1_conv1_weight: \"f32[512, 512, 3, 3]\", p_layer4_1_bn1_weight: \"f32[512]\", p_layer4_1_bn1_bias: \"f32[512]\", p_layer4_1_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_1_bn2_weight: \"f32[512]\", p_layer4_1_bn2_bias: \"f32[512]\", p_fc_weight: \"f32[1000, 512]\", p_fc_bias: \"f32[1000]\", b_bn1_running_mean: \"f32[64]\", b_bn1_running_var: \"f32[64]\", b_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn1_running_mean: \"f32[64]\", b_layer1_0_bn1_running_var: \"f32[64]\", b_layer1_0_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn2_running_mean: \"f32[64]\", b_layer1_0_bn2_running_var: \"f32[64]\", b_layer1_0_bn2_num_batches_tracked: \"i64[]\", b_layer1_1_bn1_running_mean: \"f32[64]\", b_layer1_1_bn1_running_var: \"f32[64]\", b_layer1_1_bn1_num_batches_tracked: \"i64[]\", b_layer1_1_bn2_running_mean: \"f32[64]\", b_layer1_1_bn2_running_var: \"f32[64]\", b_layer1_1_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_bn1_running_mean: \"f32[128]\", b_layer2_0_bn1_running_var: \"f32[128]\", b_layer2_0_bn1_num_batches_tracked: \"i64[]\", b_layer2_0_bn2_running_mean: \"f32[128]\", b_layer2_0_bn2_running_var: \"f32[128]\", b_layer2_0_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_downsample_1_running_mean: \"f32[128]\", b_layer2_0_downsample_1_running_var: \"f32[128]\", b_layer2_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer2_1_bn1_running_mean: \"f32[128]\", b_layer2_1_bn1_running_var: \"f32[128]\", b_layer2_1_bn1_num_batches_tracked: \"i64[]\", b_layer2_1_bn2_running_mean: \"f32[128]\", b_layer2_1_bn2_running_var: \"f32[128]\", b_layer2_1_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_bn1_running_mean: \"f32[256]\", b_layer3_0_bn1_running_var: \"f32[256]\", b_layer3_0_bn1_num_batches_tracked: \"i64[]\", b_layer3_0_bn2_running_mean: \"f32[256]\", b_layer3_0_bn2_running_var: \"f32[256]\", b_layer3_0_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_downsample_1_running_mean: \"f32[256]\", b_layer3_0_downsample_1_running_var: \"f32[256]\", b_layer3_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer3_1_bn1_running_mean: \"f32[256]\", b_layer3_1_bn1_running_var: \"f32[256]\", b_layer3_1_bn1_num_batches_tracked: \"i64[]\", b_layer3_1_bn2_running_mean: \"f32[256]\", b_layer3_1_bn2_running_var: \"f32[256]\", b_layer3_1_bn2_num_batches_tracked: \"i64[]\", b_layer4_0_bn1_running_mean: \"f32[512]\", b_layer4_0_bn1_running_var: \"f32[512]\", b_layer4_0_bn1_num_batches_tracked: \"i64[]\", b_layer4_0_bn2_running_mean: \"f32[512]\", b_layer4_0_bn2_running_var: \"f32[512]\", b_layer4_0_bn2_num_batches_tracked: \"i64[]\", b_layer4_0_downsample_1_running_mean: \"f32[512]\", b_layer4_0_downsample_1_running_var: \"f32[512]\", b_layer4_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer4_1_bn1_running_mean: \"f32[512]\", b_layer4_1_bn1_running_var: \"f32[512]\", b_layer4_1_bn1_num_batches_tracked: \"i64[]\", b_layer4_1_bn2_running_mean: \"f32[512]\", b_layer4_1_bn2_running_var: \"f32[512]\", b_layer4_1_bn2_num_batches_tracked: \"i64[]\", x: \"f32[s77, 3, 224, 224]\"):\n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d: \"f32[s77, 64, 112, 112]\" = torch.ops.aten.conv2d.default(x, p_conv1_weight, None, [2, 2], [3, 3]);  x = p_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_bn1_weight, p_bn1_bias, b_bn1_running_mean, b_bn1_running_var, 0.1, 1e-05);  conv2d = p_bn1_weight = p_bn1_bias = b_bn1_running_mean = b_bn1_running_var = None\n",
              "                    getitem: \"f32[1, 64, 112, 112]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu: \"f32[1, 64, 112, 112]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/pooling.py:226 in forward, code: return F.max_pool2d(\n",
              "                    max_pool2d: \"f32[1, 64, 56, 56]\" = torch.ops.aten.max_pool2d.default(relu, [3, 3], [2, 2], [1, 1]);  relu = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(max_pool2d, p_layer1_0_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_layer1_0_bn1_weight, p_layer1_0_bn1_bias, b_layer1_0_bn1_running_mean, b_layer1_0_bn1_running_var, 0.1, 1e-05);  conv2d_1 = p_layer1_0_bn1_weight = p_layer1_0_bn1_bias = b_layer1_0_bn1_running_mean = b_layer1_0_bn1_running_var = None\n",
              "                    getitem_3: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_1, p_layer1_0_conv2_weight, None, [1, 1], [1, 1]);  relu_1 = p_layer1_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_layer1_0_bn2_weight, p_layer1_0_bn2_bias, b_layer1_0_bn2_running_mean, b_layer1_0_bn2_running_var, 0.1, 1e-05);  conv2d_2 = p_layer1_0_bn2_weight = p_layer1_0_bn2_bias = b_layer1_0_bn2_running_mean = b_layer1_0_bn2_running_var = None\n",
              "                    getitem_6: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_5: \"f32[1, 64, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_6, max_pool2d);  getitem_6 = max_pool2d = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(add_5);  add_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_3: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_2, p_layer1_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_layer1_1_bn1_weight, p_layer1_1_bn1_bias, b_layer1_1_bn1_running_mean, b_layer1_1_bn1_running_var, 0.1, 1e-05);  conv2d_3 = p_layer1_1_bn1_weight = p_layer1_1_bn1_bias = b_layer1_1_bn1_running_mean = b_layer1_1_bn1_running_var = None\n",
              "                    getitem_9: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_3: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_9);  getitem_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_4: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_3, p_layer1_1_conv2_weight, None, [1, 1], [1, 1]);  relu_3 = p_layer1_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_layer1_1_bn2_weight, p_layer1_1_bn2_bias, b_layer1_1_bn2_running_mean, b_layer1_1_bn2_running_var, 0.1, 1e-05);  conv2d_4 = p_layer1_1_bn2_weight = p_layer1_1_bn2_bias = b_layer1_1_bn2_running_mean = b_layer1_1_bn2_running_var = None\n",
              "                    getitem_12: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_6: \"f32[1, 64, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_12, relu_2);  getitem_12 = relu_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_4: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(add_6);  add_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_5: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_4, p_layer2_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer2_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_layer2_0_bn1_weight, p_layer2_0_bn1_bias, b_layer2_0_bn1_running_mean, b_layer2_0_bn1_running_var, 0.1, 1e-05);  conv2d_5 = p_layer2_0_bn1_weight = p_layer2_0_bn1_bias = b_layer2_0_bn1_running_mean = b_layer2_0_bn1_running_var = None\n",
              "                    getitem_15: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_5: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_6: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_5, p_layer2_0_conv2_weight, None, [1, 1], [1, 1]);  relu_5 = p_layer2_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_layer2_0_bn2_weight, p_layer2_0_bn2_bias, b_layer2_0_bn2_running_mean, b_layer2_0_bn2_running_var, 0.1, 1e-05);  conv2d_6 = p_layer2_0_bn2_weight = p_layer2_0_bn2_bias = b_layer2_0_bn2_running_mean = b_layer2_0_bn2_running_var = None\n",
              "                    getitem_18: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_7: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_4, p_layer2_0_downsample_0_weight, None, [2, 2]);  relu_4 = p_layer2_0_downsample_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_layer2_0_downsample_1_weight, p_layer2_0_downsample_1_bias, b_layer2_0_downsample_1_running_mean, b_layer2_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_7 = p_layer2_0_downsample_1_weight = p_layer2_0_downsample_1_bias = b_layer2_0_downsample_1_running_mean = b_layer2_0_downsample_1_running_var = None\n",
              "                    getitem_21: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_7: \"f32[1, 128, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_18, getitem_21);  getitem_18 = getitem_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_6: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(add_7);  add_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_8: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_6, p_layer2_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer2_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_layer2_1_bn1_weight, p_layer2_1_bn1_bias, b_layer2_1_bn1_running_mean, b_layer2_1_bn1_running_var, 0.1, 1e-05);  conv2d_8 = p_layer2_1_bn1_weight = p_layer2_1_bn1_bias = b_layer2_1_bn1_running_mean = b_layer2_1_bn1_running_var = None\n",
              "                    getitem_24: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_7: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_9: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_7, p_layer2_1_conv2_weight, None, [1, 1], [1, 1]);  relu_7 = p_layer2_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_layer2_1_bn2_weight, p_layer2_1_bn2_bias, b_layer2_1_bn2_running_mean, b_layer2_1_bn2_running_var, 0.1, 1e-05);  conv2d_9 = p_layer2_1_bn2_weight = p_layer2_1_bn2_bias = b_layer2_1_bn2_running_mean = b_layer2_1_bn2_running_var = None\n",
              "                    getitem_27: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_8: \"f32[1, 128, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_27, relu_6);  getitem_27 = relu_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_8: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(add_8);  add_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_10: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_8, p_layer3_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer3_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_layer3_0_bn1_weight, p_layer3_0_bn1_bias, b_layer3_0_bn1_running_mean, b_layer3_0_bn1_running_var, 0.1, 1e-05);  conv2d_10 = p_layer3_0_bn1_weight = p_layer3_0_bn1_bias = b_layer3_0_bn1_running_mean = b_layer3_0_bn1_running_var = None\n",
              "                    getitem_30: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_9: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_30);  getitem_30 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_11: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_9, p_layer3_0_conv2_weight, None, [1, 1], [1, 1]);  relu_9 = p_layer3_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_layer3_0_bn2_weight, p_layer3_0_bn2_bias, b_layer3_0_bn2_running_mean, b_layer3_0_bn2_running_var, 0.1, 1e-05);  conv2d_11 = p_layer3_0_bn2_weight = p_layer3_0_bn2_bias = b_layer3_0_bn2_running_mean = b_layer3_0_bn2_running_var = None\n",
              "                    getitem_33: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_12: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_8, p_layer3_0_downsample_0_weight, None, [2, 2]);  relu_8 = p_layer3_0_downsample_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_layer3_0_downsample_1_weight, p_layer3_0_downsample_1_bias, b_layer3_0_downsample_1_running_mean, b_layer3_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_12 = p_layer3_0_downsample_1_weight = p_layer3_0_downsample_1_bias = b_layer3_0_downsample_1_running_mean = b_layer3_0_downsample_1_running_var = None\n",
              "                    getitem_36: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_9: \"f32[1, 256, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_33, getitem_36);  getitem_33 = getitem_36 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_10: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(add_9);  add_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_13: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_10, p_layer3_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer3_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_layer3_1_bn1_weight, p_layer3_1_bn1_bias, b_layer3_1_bn1_running_mean, b_layer3_1_bn1_running_var, 0.1, 1e-05);  conv2d_13 = p_layer3_1_bn1_weight = p_layer3_1_bn1_bias = b_layer3_1_bn1_running_mean = b_layer3_1_bn1_running_var = None\n",
              "                    getitem_39: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_11: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_39);  getitem_39 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_14: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_11, p_layer3_1_conv2_weight, None, [1, 1], [1, 1]);  relu_11 = p_layer3_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_layer3_1_bn2_weight, p_layer3_1_bn2_bias, b_layer3_1_bn2_running_mean, b_layer3_1_bn2_running_var, 0.1, 1e-05);  conv2d_14 = p_layer3_1_bn2_weight = p_layer3_1_bn2_bias = b_layer3_1_bn2_running_mean = b_layer3_1_bn2_running_var = None\n",
              "                    getitem_42: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_10: \"f32[1, 256, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_42, relu_10);  getitem_42 = relu_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_12: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(add_10);  add_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_15: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_12, p_layer4_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer4_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_layer4_0_bn1_weight, p_layer4_0_bn1_bias, b_layer4_0_bn1_running_mean, b_layer4_0_bn1_running_var, 0.1, 1e-05);  conv2d_15 = p_layer4_0_bn1_weight = p_layer4_0_bn1_bias = b_layer4_0_bn1_running_mean = b_layer4_0_bn1_running_var = None\n",
              "                    getitem_45: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_13: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_45);  getitem_45 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_16: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_13, p_layer4_0_conv2_weight, None, [1, 1], [1, 1]);  relu_13 = p_layer4_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_layer4_0_bn2_weight, p_layer4_0_bn2_bias, b_layer4_0_bn2_running_mean, b_layer4_0_bn2_running_var, 0.1, 1e-05);  conv2d_16 = p_layer4_0_bn2_weight = p_layer4_0_bn2_bias = b_layer4_0_bn2_running_mean = b_layer4_0_bn2_running_var = None\n",
              "                    getitem_48: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_17: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_12, p_layer4_0_downsample_0_weight, None, [2, 2]);  relu_12 = p_layer4_0_downsample_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_layer4_0_downsample_1_weight, p_layer4_0_downsample_1_bias, b_layer4_0_downsample_1_running_mean, b_layer4_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_17 = p_layer4_0_downsample_1_weight = p_layer4_0_downsample_1_bias = b_layer4_0_downsample_1_running_mean = b_layer4_0_downsample_1_running_var = None\n",
              "                    getitem_51: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_11: \"f32[1, 512, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_48, getitem_51);  getitem_48 = getitem_51 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_14: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(add_11);  add_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_18: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_14, p_layer4_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer4_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_layer4_1_bn1_weight, p_layer4_1_bn1_bias, b_layer4_1_bn1_running_mean, b_layer4_1_bn1_running_var, 0.1, 1e-05);  conv2d_18 = p_layer4_1_bn1_weight = p_layer4_1_bn1_bias = b_layer4_1_bn1_running_mean = b_layer4_1_bn1_running_var = None\n",
              "                    getitem_54: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_15: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_54);  getitem_54 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_19: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_15, p_layer4_1_conv2_weight, None, [1, 1], [1, 1]);  relu_15 = p_layer4_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_layer4_1_bn2_weight, p_layer4_1_bn2_bias, b_layer4_1_bn2_running_mean, b_layer4_1_bn2_running_var, 0.1, 1e-05);  conv2d_19 = p_layer4_1_bn2_weight = p_layer4_1_bn2_bias = b_layer4_1_bn2_running_mean = b_layer4_1_bn2_running_var = None\n",
              "                    getitem_57: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:102 in forward, code: out += identity\n",
              "                    add_12: \"f32[1, 512, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_57, relu_14);  getitem_57 = relu_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_16: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(add_12);  add_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
              "                    mean: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(relu_16, [-1, -2], True);  relu_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py:285 in forward, code: return self._forward_impl(x)\n",
              "                    view: \"f32[1, 512]\" = torch.ops.aten.view.default(mean, [1, 512]);  mean = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear: \"f32[1, 1000]\" = torch.ops.aten.linear.default(view, p_fc_weight, p_fc_bias);  view = p_fc_weight = p_fc_bias = None\n",
              "                    return (linear,)\n",
              "            \n",
              "        Graph signature: \n",
              "            # inputs\n",
              "            p_conv1_weight: PARAMETER target='conv1.weight'\n",
              "            p_bn1_weight: PARAMETER target='bn1.weight'\n",
              "            p_bn1_bias: PARAMETER target='bn1.bias'\n",
              "            p_layer1_0_conv1_weight: PARAMETER target='layer1.0.conv1.weight'\n",
              "            p_layer1_0_bn1_weight: PARAMETER target='layer1.0.bn1.weight'\n",
              "            p_layer1_0_bn1_bias: PARAMETER target='layer1.0.bn1.bias'\n",
              "            p_layer1_0_conv2_weight: PARAMETER target='layer1.0.conv2.weight'\n",
              "            p_layer1_0_bn2_weight: PARAMETER target='layer1.0.bn2.weight'\n",
              "            p_layer1_0_bn2_bias: PARAMETER target='layer1.0.bn2.bias'\n",
              "            p_layer1_1_conv1_weight: PARAMETER target='layer1.1.conv1.weight'\n",
              "            p_layer1_1_bn1_weight: PARAMETER target='layer1.1.bn1.weight'\n",
              "            p_layer1_1_bn1_bias: PARAMETER target='layer1.1.bn1.bias'\n",
              "            p_layer1_1_conv2_weight: PARAMETER target='layer1.1.conv2.weight'\n",
              "            p_layer1_1_bn2_weight: PARAMETER target='layer1.1.bn2.weight'\n",
              "            p_layer1_1_bn2_bias: PARAMETER target='layer1.1.bn2.bias'\n",
              "            p_layer2_0_conv1_weight: PARAMETER target='layer2.0.conv1.weight'\n",
              "            p_layer2_0_bn1_weight: PARAMETER target='layer2.0.bn1.weight'\n",
              "            p_layer2_0_bn1_bias: PARAMETER target='layer2.0.bn1.bias'\n",
              "            p_layer2_0_conv2_weight: PARAMETER target='layer2.0.conv2.weight'\n",
              "            p_layer2_0_bn2_weight: PARAMETER target='layer2.0.bn2.weight'\n",
              "            p_layer2_0_bn2_bias: PARAMETER target='layer2.0.bn2.bias'\n",
              "            p_layer2_0_downsample_0_weight: PARAMETER target='layer2.0.downsample.0.weight'\n",
              "            p_layer2_0_downsample_1_weight: PARAMETER target='layer2.0.downsample.1.weight'\n",
              "            p_layer2_0_downsample_1_bias: PARAMETER target='layer2.0.downsample.1.bias'\n",
              "            p_layer2_1_conv1_weight: PARAMETER target='layer2.1.conv1.weight'\n",
              "            p_layer2_1_bn1_weight: PARAMETER target='layer2.1.bn1.weight'\n",
              "            p_layer2_1_bn1_bias: PARAMETER target='layer2.1.bn1.bias'\n",
              "            p_layer2_1_conv2_weight: PARAMETER target='layer2.1.conv2.weight'\n",
              "            p_layer2_1_bn2_weight: PARAMETER target='layer2.1.bn2.weight'\n",
              "            p_layer2_1_bn2_bias: PARAMETER target='layer2.1.bn2.bias'\n",
              "            p_layer3_0_conv1_weight: PARAMETER target='layer3.0.conv1.weight'\n",
              "            p_layer3_0_bn1_weight: PARAMETER target='layer3.0.bn1.weight'\n",
              "            p_layer3_0_bn1_bias: PARAMETER target='layer3.0.bn1.bias'\n",
              "            p_layer3_0_conv2_weight: PARAMETER target='layer3.0.conv2.weight'\n",
              "            p_layer3_0_bn2_weight: PARAMETER target='layer3.0.bn2.weight'\n",
              "            p_layer3_0_bn2_bias: PARAMETER target='layer3.0.bn2.bias'\n",
              "            p_layer3_0_downsample_0_weight: PARAMETER target='layer3.0.downsample.0.weight'\n",
              "            p_layer3_0_downsample_1_weight: PARAMETER target='layer3.0.downsample.1.weight'\n",
              "            p_layer3_0_downsample_1_bias: PARAMETER target='layer3.0.downsample.1.bias'\n",
              "            p_layer3_1_conv1_weight: PARAMETER target='layer3.1.conv1.weight'\n",
              "            p_layer3_1_bn1_weight: PARAMETER target='layer3.1.bn1.weight'\n",
              "            p_layer3_1_bn1_bias: PARAMETER target='layer3.1.bn1.bias'\n",
              "            p_layer3_1_conv2_weight: PARAMETER target='layer3.1.conv2.weight'\n",
              "            p_layer3_1_bn2_weight: PARAMETER target='layer3.1.bn2.weight'\n",
              "            p_layer3_1_bn2_bias: PARAMETER target='layer3.1.bn2.bias'\n",
              "            p_layer4_0_conv1_weight: PARAMETER target='layer4.0.conv1.weight'\n",
              "            p_layer4_0_bn1_weight: PARAMETER target='layer4.0.bn1.weight'\n",
              "            p_layer4_0_bn1_bias: PARAMETER target='layer4.0.bn1.bias'\n",
              "            p_layer4_0_conv2_weight: PARAMETER target='layer4.0.conv2.weight'\n",
              "            p_layer4_0_bn2_weight: PARAMETER target='layer4.0.bn2.weight'\n",
              "            p_layer4_0_bn2_bias: PARAMETER target='layer4.0.bn2.bias'\n",
              "            p_layer4_0_downsample_0_weight: PARAMETER target='layer4.0.downsample.0.weight'\n",
              "            p_layer4_0_downsample_1_weight: PARAMETER target='layer4.0.downsample.1.weight'\n",
              "            p_layer4_0_downsample_1_bias: PARAMETER target='layer4.0.downsample.1.bias'\n",
              "            p_layer4_1_conv1_weight: PARAMETER target='layer4.1.conv1.weight'\n",
              "            p_layer4_1_bn1_weight: PARAMETER target='layer4.1.bn1.weight'\n",
              "            p_layer4_1_bn1_bias: PARAMETER target='layer4.1.bn1.bias'\n",
              "            p_layer4_1_conv2_weight: PARAMETER target='layer4.1.conv2.weight'\n",
              "            p_layer4_1_bn2_weight: PARAMETER target='layer4.1.bn2.weight'\n",
              "            p_layer4_1_bn2_bias: PARAMETER target='layer4.1.bn2.bias'\n",
              "            p_fc_weight: PARAMETER target='fc.weight'\n",
              "            p_fc_bias: PARAMETER target='fc.bias'\n",
              "            b_bn1_running_mean: BUFFER target='bn1.running_mean' persistent=True\n",
              "            b_bn1_running_var: BUFFER target='bn1.running_var' persistent=True\n",
              "            b_bn1_num_batches_tracked: BUFFER target='bn1.num_batches_tracked' persistent=True\n",
              "            b_layer1_0_bn1_running_mean: BUFFER target='layer1.0.bn1.running_mean' persistent=True\n",
              "            b_layer1_0_bn1_running_var: BUFFER target='layer1.0.bn1.running_var' persistent=True\n",
              "            b_layer1_0_bn1_num_batches_tracked: BUFFER target='layer1.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer1_0_bn2_running_mean: BUFFER target='layer1.0.bn2.running_mean' persistent=True\n",
              "            b_layer1_0_bn2_running_var: BUFFER target='layer1.0.bn2.running_var' persistent=True\n",
              "            b_layer1_0_bn2_num_batches_tracked: BUFFER target='layer1.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer1_1_bn1_running_mean: BUFFER target='layer1.1.bn1.running_mean' persistent=True\n",
              "            b_layer1_1_bn1_running_var: BUFFER target='layer1.1.bn1.running_var' persistent=True\n",
              "            b_layer1_1_bn1_num_batches_tracked: BUFFER target='layer1.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer1_1_bn2_running_mean: BUFFER target='layer1.1.bn2.running_mean' persistent=True\n",
              "            b_layer1_1_bn2_running_var: BUFFER target='layer1.1.bn2.running_var' persistent=True\n",
              "            b_layer1_1_bn2_num_batches_tracked: BUFFER target='layer1.1.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer2_0_bn1_running_mean: BUFFER target='layer2.0.bn1.running_mean' persistent=True\n",
              "            b_layer2_0_bn1_running_var: BUFFER target='layer2.0.bn1.running_var' persistent=True\n",
              "            b_layer2_0_bn1_num_batches_tracked: BUFFER target='layer2.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer2_0_bn2_running_mean: BUFFER target='layer2.0.bn2.running_mean' persistent=True\n",
              "            b_layer2_0_bn2_running_var: BUFFER target='layer2.0.bn2.running_var' persistent=True\n",
              "            b_layer2_0_bn2_num_batches_tracked: BUFFER target='layer2.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer2_0_downsample_1_running_mean: BUFFER target='layer2.0.downsample.1.running_mean' persistent=True\n",
              "            b_layer2_0_downsample_1_running_var: BUFFER target='layer2.0.downsample.1.running_var' persistent=True\n",
              "            b_layer2_0_downsample_1_num_batches_tracked: BUFFER target='layer2.0.downsample.1.num_batches_tracked' persistent=True\n",
              "            b_layer2_1_bn1_running_mean: BUFFER target='layer2.1.bn1.running_mean' persistent=True\n",
              "            b_layer2_1_bn1_running_var: BUFFER target='layer2.1.bn1.running_var' persistent=True\n",
              "            b_layer2_1_bn1_num_batches_tracked: BUFFER target='layer2.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer2_1_bn2_running_mean: BUFFER target='layer2.1.bn2.running_mean' persistent=True\n",
              "            b_layer2_1_bn2_running_var: BUFFER target='layer2.1.bn2.running_var' persistent=True\n",
              "            b_layer2_1_bn2_num_batches_tracked: BUFFER target='layer2.1.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_0_bn1_running_mean: BUFFER target='layer3.0.bn1.running_mean' persistent=True\n",
              "            b_layer3_0_bn1_running_var: BUFFER target='layer3.0.bn1.running_var' persistent=True\n",
              "            b_layer3_0_bn1_num_batches_tracked: BUFFER target='layer3.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_0_bn2_running_mean: BUFFER target='layer3.0.bn2.running_mean' persistent=True\n",
              "            b_layer3_0_bn2_running_var: BUFFER target='layer3.0.bn2.running_var' persistent=True\n",
              "            b_layer3_0_bn2_num_batches_tracked: BUFFER target='layer3.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_0_downsample_1_running_mean: BUFFER target='layer3.0.downsample.1.running_mean' persistent=True\n",
              "            b_layer3_0_downsample_1_running_var: BUFFER target='layer3.0.downsample.1.running_var' persistent=True\n",
              "            b_layer3_0_downsample_1_num_batches_tracked: BUFFER target='layer3.0.downsample.1.num_batches_tracked' persistent=True\n",
              "            b_layer3_1_bn1_running_mean: BUFFER target='layer3.1.bn1.running_mean' persistent=True\n",
              "            b_layer3_1_bn1_running_var: BUFFER target='layer3.1.bn1.running_var' persistent=True\n",
              "            b_layer3_1_bn1_num_batches_tracked: BUFFER target='layer3.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_1_bn2_running_mean: BUFFER target='layer3.1.bn2.running_mean' persistent=True\n",
              "            b_layer3_1_bn2_running_var: BUFFER target='layer3.1.bn2.running_var' persistent=True\n",
              "            b_layer3_1_bn2_num_batches_tracked: BUFFER target='layer3.1.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer4_0_bn1_running_mean: BUFFER target='layer4.0.bn1.running_mean' persistent=True\n",
              "            b_layer4_0_bn1_running_var: BUFFER target='layer4.0.bn1.running_var' persistent=True\n",
              "            b_layer4_0_bn1_num_batches_tracked: BUFFER target='layer4.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer4_0_bn2_running_mean: BUFFER target='layer4.0.bn2.running_mean' persistent=True\n",
              "            b_layer4_0_bn2_running_var: BUFFER target='layer4.0.bn2.running_var' persistent=True\n",
              "            b_layer4_0_bn2_num_batches_tracked: BUFFER target='layer4.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer4_0_downsample_1_running_mean: BUFFER target='layer4.0.downsample.1.running_mean' persistent=True\n",
              "            b_layer4_0_downsample_1_running_var: BUFFER target='layer4.0.downsample.1.running_var' persistent=True\n",
              "            b_layer4_0_downsample_1_num_batches_tracked: BUFFER target='layer4.0.downsample.1.num_batches_tracked' persistent=True\n",
              "            b_layer4_1_bn1_running_mean: BUFFER target='layer4.1.bn1.running_mean' persistent=True\n",
              "            b_layer4_1_bn1_running_var: BUFFER target='layer4.1.bn1.running_var' persistent=True\n",
              "            b_layer4_1_bn1_num_batches_tracked: BUFFER target='layer4.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer4_1_bn2_running_mean: BUFFER target='layer4.1.bn2.running_mean' persistent=True\n",
              "            b_layer4_1_bn2_running_var: BUFFER target='layer4.1.bn2.running_var' persistent=True\n",
              "            b_layer4_1_bn2_num_batches_tracked: BUFFER target='layer4.1.bn2.num_batches_tracked' persistent=True\n",
              "            x: USER_INPUT\n",
              "    \n",
              "            # outputs\n",
              "            linear: USER_OUTPUT\n",
              "    \n",
              "        Range constraints: {s77: VR[0, int_oo]}\n",
              "\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify and get tensor names\n",
        "onnx_model = onnx.load(model_file)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "input_name = onnx_model.graph.input[0].name\n",
        "output_name = onnx_model.graph.output[0].name\n",
        "print(f\"✅ ONNX model created and checked successfully. Input name: {input_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a70cgv8QuCQ2",
        "outputId": "0d08068f-8b5f-40c2-a810-90e6db1d9910"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ONNX model created and checked successfully. Input name: input_tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy input data (a single batch of an image)\n",
        "input_data = np.random.rand(*input_shape).astype(np.float32)\n",
        "input_feed = {input_name: input_data}\n",
        "\n",
        "# Define the providers, prioritizing TensorRT\n",
        "providers = [\n",
        "    ('TensorrtExecutionProvider', {\n",
        "        'device_id': 0,\n",
        "        'trt_fp16_enable': True, # Use faster FP16 precision (recommended on modern GPUs)\n",
        "        'trt_max_workspace_size': 2147483648 # 2GB workspace limit\n",
        "    }),\n",
        "    'CUDAExecutionProvider' # Fallback to standard CUDA if TRT fails\n",
        "]\n",
        "\n",
        "print(\"\\n--- Starting TensorRT Accelerated Session ---\")\n",
        "try:\n",
        "    # Create the Inference Session\n",
        "    sess_trt = ort.InferenceSession(model_file, providers = providers)\n",
        "\n",
        "    # Check if the TensorRT provider was successfully loaded\n",
        "    if 'TensorrtExecutionProvider' in sess_trt.get_providers():\n",
        "        print(\"✅ Session successfully loaded with TensorRT EP.\")\n",
        "    else:\n",
        "        # This is a safe check if TRT is available, but ORT sometimes abstracts this\n",
        "        print(\"⚠️ Warning: TensorRT EP may not be the active provider. Check your GPU/CUDA versions.\")\n",
        "\n",
        "    # 🚀 Run the **First Inference (Warmup)** 🚀\n",
        "    # This is the necessary, slow step where TensorRT compiles the optimized engine.\n",
        "    print(\"Warming up (building TensorRT engine - this will be slow)...\")\n",
        "    start_time_build = time.time()\n",
        "    _ = sess_trt.run([output_name], input_feed)\n",
        "    build_time = time.time() - start_time_build\n",
        "    print(f\"TensorRT Engine build/warmup time: {build_time:.4f} seconds\")\n",
        "\n",
        "    # ⚡ Run Accelerated Inference ⚡\n",
        "    # Subsequent runs use the compiled engine and demonstrate acceleration.\n",
        "    num_runs = 50\n",
        "    runtimes = []\n",
        "    print(f\"Running {num_runs} accelerated inferences for timing...\")\n",
        "    for _ in range(num_runs):\n",
        "        start_time_inf = time.time()\n",
        "        output_trt = sess_trt.run([output_name], input_feed)\n",
        "        runtimes.append(time.time() - start_time_inf)\n",
        "\n",
        "    avg_inf_time = np.mean(runtimes)\n",
        "    print(f\"\\n--- TensorRT Inference Results ---\")\n",
        "    print(f\"Average accelerated inference time: {avg_inf_time * 1000:.2f} ms\")\n",
        "    print(f\"Output tensor shape: {output_trt[0].shape}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Final error during TensorRT inference: {e}\")\n",
        "    print(\"Ensure all cells have been run in a GPU runtime.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm9QJaIXuET5",
        "outputId": "d9c629b7-3f27-48c5-d9e6-466685ad1261"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting TensorRT Accelerated Session ---\n",
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:560 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using [('TensorrtExecutionProvider', {'device_id': 0, 'trt_fp16_enable': True, 'trt_max_workspace_size': 2147483648}), 'CUDAExecutionProvider']\n",
            "Falling back to ['CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "⚠️ Warning: TensorRT EP may not be the active provider. Check your GPU/CUDA versions.\n",
            "Warming up (building TensorRT engine - this will be slow)...\n",
            "TensorRT Engine build/warmup time: 0.0757 seconds\n",
            "Running 50 accelerated inferences for timing...\n",
            "\n",
            "--- TensorRT Inference Results ---\n",
            "Average accelerated inference time: 47.27 ms\n",
            "Output tensor shape: (1, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization\n",
        "### Sequence truncation"
      ],
      "metadata": {
        "id": "tqCJWyFG2cn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "text = \"This is a very long sentence that will be truncated by the tokenizer.\"\n",
        "max_length = 10\n",
        "\n",
        "encoded = tokenizer(text, truncation=True, max_length=max_length)\n",
        "print(encoded['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL5VsCD9uHlZ",
        "outputId": "1b1df0d9-380f-4601-d534-8ec107c07916"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 2023, 2003, 1037, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Static\n",
        "encoded = tokenizer([\"short\", \"a much longer sentence\",\"A quick brown fox jumps over a lazy short dog\"],\n",
        "                    padding='max_length',\n",
        "                    max_length=10)\n",
        "print(encoded['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksduDdl-3Lfo",
        "outputId": "96d5758b-6c58-445c-afdf-de6577d1e30a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101, 2460, 102, 0, 0, 0, 0, 0, 0, 0], [101, 1037, 2172, 2936, 6251, 102, 0, 0, 0, 0], [101, 1037, 4248, 2829, 4419, 14523, 2058, 1037, 13971, 2460, 3899, 102]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic\n",
        "encoded = tokenizer([\"short\", \"a much longer sentence\"],\n",
        "                    padding='longest')\n",
        "print(encoded['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_41S5gtw4g-Y",
        "outputId": "3427cea1-86f9-4061-9ed8-7a89cbaabb7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101, 2460, 102, 0, 0, 0], [101, 1037, 2172, 2936, 6251, 102]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Example: T5 or XLM-R both use SentencePiece\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "tokens = tokenizer.tokenize(\"This is an example sentence.\")\n",
        "print(\"SentencePiece Tokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "cc0569076697426d91e9f747771b3d64",
            "f922fd701d924138946601803d880ba9",
            "7489d8e4cc3d45c7bf2bdf57b7db57c3",
            "50311600339f4a9a91899a7d09244010",
            "51fdb7c3ce704b5880d69fd2a0b30b49",
            "0e86c9b5462c4bbeb07996c80fb22304",
            "06dd46170651417dbe0ca1fd75476f9e",
            "24760f9ec78b4173839f40c8effa084d",
            "3c7981c368854b18ab206f260e309619",
            "5ed2106e33714fe083907b94fcef8f79",
            "989fc79e0ebe48a68b3bff39175c79ec",
            "992d9be7abb1435e8098b0c8bd96bebe",
            "9a8e441c20d44278b465ffeab1c09eda",
            "66c36626b8b44000ab0144632cce4bb9",
            "69d82a104d6d492391d99360e948244e",
            "8b94ae3516e5411f8246938c1cbb8b2d",
            "f57af1983ae74f64934c88cf1382987c",
            "3be50272f3e74f35a67fb4a55fe8acb2",
            "529ea5240f4a49e3b04c49531e854b70",
            "9318bd1f7d594091a5226e334f6843dc",
            "ec19137b6d9146298351bd2b19b8eef0",
            "f926ef388d6841a3aac537ee430a1377",
            "948c420188d94005ac47bc4c3fa25e8d",
            "ef60e8083c234173b3f0f5b5448eb8c2",
            "703b0d4a3e5f4d78ab3b0a1d6d3f793e",
            "577af18bbd484cff80206a9a4ef366ab",
            "7501381610794b768bbdc791e32eb177",
            "06dbc484ada74f4e9ed37536d4f26fc2",
            "fecdfa6dce5e4b1ead864cf7b5ace577",
            "db95c1660a414dce95c9c7139ec1f685",
            "beddbfc939624627956376afb7a78d50",
            "5f0f739c0a7444aead8324453accb0e6",
            "7e5ee752c53743cab5df88a7e98162b2"
          ]
        },
        "id": "eO-frHqP4zBU",
        "outputId": "409619f5-a427-49e7-d6d4-25146125e322"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc0569076697426d91e9f747771b3d64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "992d9be7abb1435e8098b0c8bd96bebe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "948c420188d94005ac47bc4c3fa25e8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentencePiece Tokens: ['▁This', '▁is', '▁an', '▁example', '▁sentence', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer, BertWordPieceTokenizer"
      ],
      "metadata": {
        "id": "efUoq36B9o8c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "# Step 1: Define some example text (no file needed)\n",
        "corpus = [\n",
        "    \"Tokenization is a core step in NLP.\",\n",
        "    \"It splits text into smaller pieces called tokens.\",\n",
        "    \"These tokens help models like BERT understand meaning.\"\n",
        "]\n",
        "\n",
        "# Step 2: Save to a temporary text file (required by tokenizer)\n",
        "# Unfortunately, the current Tokenizers library still needs a file-like input for training.\n",
        "# But we can create it dynamically inside Python without manually saving one.\n",
        "\n",
        "with open(\"temp_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in corpus:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "# Step 3: Initialize and train tokenizer\n",
        "tokenizer = BertWordPieceTokenizer(lowercase = True)\n",
        "tokenizer.train(\n",
        "    files = \"temp_corpus.txt\",\n",
        "    vocab_size = 100,\n",
        "    min_frequency = 1,\n",
        ")\n",
        "\n",
        "# Step 4: Use tokenizer directly (no reloading from vocab.txt)\n",
        "encoded = tokenizer.encode(\"Tokenization divides text into tokens.\")\n",
        "print(\"Tokens:\", encoded.tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A91znUEZ-RMz",
        "outputId": "a03b67fb-ae31-4c77-e241-d93640107ada"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['tokeniz', '##ati', '##on', '[UNK]', 'te', '##xt', 'into', 'tokens', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "# Step 1: Create a small example corpus\n",
        "corpus = [\n",
        "    \"Tokenization is fun and powerful.\",\n",
        "    \"Byte Pair Encoding splits words into subwords.\",\n",
        "    \"This helps handle unknown tokens effectively.\"\n",
        "]\n",
        "\n",
        "# Step 2: Write corpus to a temporary file (required by the library)\n",
        "with open(\"temp_bpe.txt\", \"w\", encoding = \"utf-8\") as f:\n",
        "    for line in corpus:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "# Step 3: Initialize and train the ByteLevelBPETokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train(\n",
        "    files = \"temp_bpe.txt\",\n",
        "    vocab_size = 100,\n",
        "    min_frequency = 1,\n",
        "    special_tokens = [\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"]\n",
        ")\n",
        "\n",
        "# Step 4: Encode a new sentence\n",
        "encoded = tokenizer.encode(\"Tokenization helps subword modeling.\")\n",
        "print(\"Tokens:\", encoded.tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO4okc3U-Z9m",
        "outputId": "6c145741-dd82-4051-eba1-e6957c548019"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['T', 'o', 'k', 'e', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n', 'Ġ', 'h', 'e', 'l', 'p', 's', 'Ġ', 's', 'u', 'b', 'w', 'o', 'r', 'd', 'Ġ', 'm', 'o', 'd', 'e', 'l', 'i', 'n', 'g', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36MUdT-Q_T4n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}